{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "sns.set()\n",
    "from PIL import Image\n",
    "from matplotlib import image\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = [cv2.imread(file) for file in glob.glob(\"\\GTSRB\\Training\\00000\\*.ppm\")]\n",
    "train_data_path = \".\\dataset\\Train.csv\"\n",
    "test_data_path = \".\\dataset\\Test.csv\"\n",
    "train_path = \"dataset\\Train\"\n",
    "\n",
    "train_data = pd.read_csv(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        20\n",
       "1        20\n",
       "2        20\n",
       "3        20\n",
       "4        20\n",
       "5        20\n",
       "6        20\n",
       "7        20\n",
       "8        20\n",
       "9        20\n",
       "10       20\n",
       "11       20\n",
       "12       20\n",
       "13       20\n",
       "14       20\n",
       "15       20\n",
       "16       20\n",
       "17       20\n",
       "18       20\n",
       "19       20\n",
       "20       20\n",
       "21       20\n",
       "22       20\n",
       "23       20\n",
       "24       20\n",
       "25       20\n",
       "26       20\n",
       "27       20\n",
       "28       20\n",
       "29       20\n",
       "         ..\n",
       "39179    42\n",
       "39180    42\n",
       "39181    42\n",
       "39182    42\n",
       "39183    42\n",
       "39184    42\n",
       "39185    42\n",
       "39186    42\n",
       "39187    42\n",
       "39188    42\n",
       "39189    42\n",
       "39190    42\n",
       "39191    42\n",
       "39192    42\n",
       "39193    42\n",
       "39194    42\n",
       "39195    42\n",
       "39196    42\n",
       "39197    42\n",
       "39198    42\n",
       "39199    42\n",
       "39200    42\n",
       "39201    42\n",
       "39202    42\n",
       "39203    42\n",
       "39204    42\n",
       "39205    42\n",
       "39206    42\n",
       "39207    42\n",
       "39208    42\n",
       "Name: ClassId, Length: 39209, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"ClassId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[18,5]);\n",
    "plt.hist(train_data[\"ClassId\"], bins=43, );\n",
    "plt.ylabel(\"Number of tarining examples\");\n",
    "plt.xlabel(\"Classes\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39209.000000</td>\n",
       "      <td>39209.000000</td>\n",
       "      <td>39209.000000</td>\n",
       "      <td>39209.000000</td>\n",
       "      <td>39209.000000</td>\n",
       "      <td>39209.000000</td>\n",
       "      <td>39209.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.835880</td>\n",
       "      <td>50.328930</td>\n",
       "      <td>5.999515</td>\n",
       "      <td>5.962381</td>\n",
       "      <td>45.197302</td>\n",
       "      <td>44.728379</td>\n",
       "      <td>15.788390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.306933</td>\n",
       "      <td>23.115423</td>\n",
       "      <td>1.475493</td>\n",
       "      <td>1.385440</td>\n",
       "      <td>23.060157</td>\n",
       "      <td>21.971145</td>\n",
       "      <td>12.013238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>243.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Width        Height        Roi.X1        Roi.Y1        Roi.X2  \\\n",
       "count  39209.000000  39209.000000  39209.000000  39209.000000  39209.000000   \n",
       "mean      50.835880     50.328930      5.999515      5.962381     45.197302   \n",
       "std       24.306933     23.115423      1.475493      1.385440     23.060157   \n",
       "min       25.000000     25.000000      0.000000      5.000000     20.000000   \n",
       "25%       35.000000     35.000000      5.000000      5.000000     29.000000   \n",
       "50%       43.000000     43.000000      6.000000      6.000000     38.000000   \n",
       "75%       58.000000     58.000000      6.000000      6.000000     53.000000   \n",
       "max      243.000000    225.000000     20.000000     20.000000    223.000000   \n",
       "\n",
       "             Roi.Y2       ClassId  \n",
       "count  39209.000000  39209.000000  \n",
       "mean      44.728379     15.788390  \n",
       "std       21.971145     12.013238  \n",
       "min       20.000000      0.000000  \n",
       "25%       30.000000      5.000000  \n",
       "50%       38.000000     12.000000  \n",
       "75%       52.000000     25.000000  \n",
       "max      205.000000     42.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Width', 'Height', 'Roi.X1', 'Roi.Y1', 'Roi.X2', 'Roi.Y2', 'ClassId',\n",
       "       'Path'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>Train/20/00020_00000_00004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId  \\\n",
       "0     27      26       5       5      22      20       20   \n",
       "1     28      27       5       6      23      22       20   \n",
       "2     29      26       6       5      24      21       20   \n",
       "3     28      27       5       6      23      22       20   \n",
       "4     28      26       5       5      23      21       20   \n",
       "\n",
       "                             Path  \n",
       "0  Train/20/00020_00000_00000.png  \n",
       "1  Train/20/00020_00000_00001.png  \n",
       "2  Train/20/00020_00000_00002.png  \n",
       "3  Train/20/00020_00000_00003.png  \n",
       "4  Train/20/00020_00000_00004.png  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing\n",
    "##### 1. Load image\n",
    "##### 2. Resize image to 32* 32\n",
    "##### 3. Convert to grayscale\n",
    "##### 4. Eqilize image for better contrast\n",
    "##### 5. Convert image between range [0 and 1]\n",
    "##### 6. Convert labels to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Installed_Softwares\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "img_dimentions = (32,32)\n",
    "def pre_processing_(train_data):\n",
    "    number_of_images = train_data.shape\n",
    "    number_of_images[0]\n",
    "\n",
    "    train_images = []\n",
    "\n",
    "    for i in range(number_of_images[0]):\n",
    "        img = cv2.imread(\"dataset/\"+train_data.Path[i])\n",
    "        img = cv2.resize(img, img_dimentions) # resizing images to 32 x 32 pixels\n",
    "        img_grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert RBG images to grayscale\n",
    "        img_equilize = cv2.equalizeHist(img_grayscale) # improve contrast\n",
    "        img_scale = img_grayscale / 255.00\n",
    "\n",
    "        train_images.append(img_scale)\n",
    "    # One- hot encoding labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(train_data.ClassId)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    train_labels = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return np.array(train_images), train_labels\n",
    "\n",
    "train_images, train_labels = pre_processing_(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation\n",
    "#### 1. Flip image horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # flipped images \n",
    "# flipped_images = []\n",
    "# flipped_labels = []\n",
    "# for i in range(train_images.shape[0]):\n",
    "#     # for horizontally flippable images\n",
    "#     if np.where(train_labels[i] == 1)[0][0] in horizontally_flippable:\n",
    "#         flipped_images.append(cv2.flip(train_images[i], flipCode=1)) # horizontal flip\n",
    "#         flipped_labels.append(train_labels[i])\n",
    "#     flipped = len(flipped_images)\n",
    "#     print(f\"Number of images flipped horizontally: {flipped} and labels: {flipped}\")\n",
    "#     # for vertically flippable images\n",
    "#     if np.where(train_labels[i] == 1)[0][0] in vertically_flippable:\n",
    "#         flipped_images.append(cv2.flip(train_images[i], flipCode=0)) # vertical flip\n",
    "#         flipped_labels.append(train_labels[i])\n",
    "#     print(f\"Number of images flipped vertically: {len(flipped_images) - flipped} and labels: {len(flipped_labels) - flipped}\")\n",
    "#     flipped = len(flipped_images)\n",
    "#     # for both flippable images\n",
    "#     if np.where(train_labels[i] == 1)[0][0] in both_flippable:\n",
    "#         flipped_images.append(cv2.flip(train_images[i], flipCode=-1)) # both flip\n",
    "#         flipped_labels.append(train_labels[i])\n",
    "#     print(f\"Number of images both flipped: {len(flipped_images) - flipped} and labels: {len(flipped_labels) - flipped}\")\n",
    "#     flipped = len(flipped_images)\n",
    "#     if np.where(train_labels[i] == 1)[0][0] in horizontally_cross_flippable[:, 0]:\n",
    "#         flipped_images.append(cv2.flip(train_images[i], flipCode=1)) # horizontally cross flip\n",
    "#         flipped_labels.append(horizontally_cross_flippable[np.where(horizontally_cross_flippable[:,0] == np.where(train_labels[i] == 1)[0][0]) ,1]  )\n",
    "#     print(f\"Number of images cross flipped horizontally: {len(flipped_images) - flipped} and labels: {len(flipped_labels) - flipped}\")\n",
    "#     flipped = len(flipped_images)\n",
    "# print(f\"Number of flipped images: {len(flipped_images)} and labels: {len(flipped_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flipped images: 24329 and labels: 24329\n"
     ]
    }
   ],
   "source": [
    "#     # Classes of signs that, when flipped horizontally, should still be classified as the same class\n",
    "horizontally_flippable = np.array([11, 12, 13, 15, 17, 18, 22, 26, 30, 35])\n",
    "# Classes of signs that, when flipped vertically, should still be classified as the same class\n",
    "vertically_flippable = np.array([1, 5, 12, 15, 17])\n",
    "# Classes of signs that, when flipped horizontally and then vertically, should still be classified as the same class\n",
    "both_flippable = np.array([32, 40])\n",
    "# Classes of signs that, when flipped horizontally, would still be meaningful, but should be classified as some other class\n",
    "horizontally_cross_flippable = np.array([\n",
    "    [19, 20], \n",
    "    [33, 34], \n",
    "    [36, 37], \n",
    "    [38, 39],\n",
    "    [20, 19], \n",
    "    [34, 33], \n",
    "    [37, 36], \n",
    "    [39, 38],   \n",
    "])\n",
    "\n",
    "# flipped images \n",
    "flipped_images = []\n",
    "flipped_labels = []\n",
    "\n",
    "## TODO: Optimize for loop\n",
    "for i in range(train_images.shape[0]):\n",
    "    # for horizontally flippable images\n",
    "    if np.where(train_labels[i] == 1)[0][0] in horizontally_flippable:\n",
    "        flipped_images.append(cv2.flip(train_images[i], flipCode=1)) # horizontal flip\n",
    "        flipped_labels.append(train_labels[i])\n",
    "#     print(type(train_labels[i]))\n",
    "    \n",
    "    # for vertically flippable images\n",
    "    if np.where(train_labels[i] == 1)[0][0] in vertically_flippable:\n",
    "        flipped_images.append(cv2.flip(train_images[i], flipCode=0)) # vertical flip\n",
    "        flipped_labels.append(train_labels[i])\n",
    "    # for both flippable images\n",
    "    if np.where(train_labels[i] == 1)[0][0] in both_flippable:\n",
    "        flipped_images.append(cv2.flip(train_images[i], flipCode=-1)) # both flip\n",
    "        flipped_labels.append(train_labels[i])\n",
    "    \n",
    "    if np.where(train_labels[i] == 1)[0][0] in horizontally_cross_flippable[:, 0]:\n",
    "        flipped_images.append(cv2.flip(train_images[i], flipCode=1)) # horizontally cross flip\n",
    "        data_label = int(horizontally_cross_flippable[np.where(horizontally_cross_flippable[:,0] == np.where(train_labels[i] == 1)[0][0]) ,1])\n",
    "        flipped_labels.append(to_categorical(data_label, num_classes=43))\n",
    "print(f\"Number of flipped images: {len(flipped_images)} and labels: {len(flipped_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.array(list(to_categorical(19, num_classes=43))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original images: 39209 and original labels: 39209\n",
      "Number of total images: 63538 and total labels: 63538\n"
     ]
    }
   ],
   "source": [
    "# Adding flipped images to original dataset\n",
    "print(f\"Number of original images: {len(train_images)} and original labels: {len(train_labels)}\")\n",
    "train_images = np.append(train_images, flipped_images, axis = 0)\n",
    "# flipped_labels = np.array(flipped_labels)\n",
    "train_labels = np.append(train_labels, flipped_labels, axis =0)\n",
    "print(f\"Number of total images: {len(train_images)} and total labels: {len(train_labels)}\")\n",
    "# train_images = train_images.append(flipped_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "# X_val\n",
    "train_images = np.reshape(train_images,(train_images.shape[0], train_images.shape[1], train_images.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train,  y_test = train_test_split(train_images, train_labels, test_size=0.30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from tensorflow.keras import models, layers\n",
    "\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Conv2D(32, kernel_size = 5, activation = \"relu\", input_shape=(32,32,1)))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(32, kernel_size=5, activation = \"relu\", input_shape=(16,16,1)))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(43))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gudek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 43)                44075     \n",
      "=================================================================\n",
      "Total params: 2,399,275\n",
      "Trainable params: 2,399,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Conv layer 1\n",
    "from tensorflow.keras import models, layers\n",
    "conv_model = models.Sequential()\n",
    "conv_model.add(layers.Conv2D(32, kernel_size=5, input_shape=(32,32,1), padding='same', activation='relu'))\n",
    "conv_model.add(layers.MaxPool2D((2,2)))\n",
    "#conv_model.add(Dropout(0.1))\n",
    "\n",
    "# Conv layer 2\n",
    "conv_model.add(layers.Conv2D(64, kernel_size=5, padding='same', activation='relu'))\n",
    "conv_model.add(layers.MaxPool2D(2,2))\n",
    "#conv_model.add(Dropout(0.2))\n",
    "\n",
    "# Conv layer 3\n",
    "conv_model.add(layers.Conv2D(128, kernel_size=5, padding='same', activation='relu'))\n",
    "conv_model.add(layers.MaxPool2D(2,2))\n",
    "#conv_model.add(Dropout(0.3))\n",
    "\n",
    "# Flatten\n",
    "conv_model.add(layers.Flatten())\n",
    "#conv_model.add(Dropout(0.5))\n",
    "\n",
    "# Fully connected layer 1:\n",
    "conv_model.add(layers.Dense(1024, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "conv_model.add(layers.Dense(43, activation='softmax'))\n",
    "\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44476 samples, validate on 19062 samples\n",
      "WARNING:tensorflow:From C:\\Users\\gudek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "44476/44476 [==============================] - 239s 5ms/sample - loss: 0.6918 - acc: 0.8109 - val_loss: 0.1373 - val_acc: 0.9558\n",
      "Epoch 2/5\n",
      "44476/44476 [==============================] - 242s 5ms/sample - loss: 0.0675 - acc: 0.9801 - val_loss: 0.0707 - val_acc: 0.9786\n",
      "Epoch 3/5\n",
      "44476/44476 [==============================] - 240s 5ms/sample - loss: 0.0405 - acc: 0.9880 - val_loss: 0.0406 - val_acc: 0.9887\n",
      "Epoch 4/5\n",
      "44476/44476 [==============================] - 241s 5ms/sample - loss: 0.0359 - acc: 0.9899 - val_loss: 0.0515 - val_acc: 0.9851\n",
      "Epoch 5/5\n",
      "44476/44476 [==============================] - 240s 5ms/sample - loss: 0.0253 - acc: 0.9928 - val_loss: 0.0571 - val_acc: 0.9849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cdb2ee2908>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "conv_model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
